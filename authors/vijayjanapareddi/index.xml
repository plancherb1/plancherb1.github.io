<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Brian Plancher</title>
    <link>https://plancherb1.github.io/authors/vijayjanapareddi/</link>
    <description>Recent content on Brian Plancher</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; {year} Brian Plancher</copyright>
    <lastBuildDate>Wed, 15 Jun 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://plancherb1.github.io/authors/vijayjanapareddi/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Tiny Robot Learning: Challenges and Directions for Machine Learning in Resource-Constrained Robots</title>
      <link>https://plancherb1.github.io/publication/tinyrobotlearning/</link>
      <pubDate>Wed, 15 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://plancherb1.github.io/publication/tinyrobotlearning/</guid>
      <description>Tiny robot learning lies at the intersection of embedded systems, robotics, and ML, compounding the challenges of these domains. This paper gives a brief survey of the tiny robot learning space, elaborates on key challenges, and proposes promising opportunities for future work in ML system design.</description>
    </item>
    
    <item>
      <title>Machine Learning Sensors</title>
      <link>https://plancherb1.github.io/publication/mlsensors/</link>
      <pubDate>Wed, 08 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://plancherb1.github.io/publication/mlsensors/</guid>
      <description>Machine learning sensors represent a paradigm shift for the future of embedded machine learning applications. Current instantiations of embedded machine learning (ML) suffer from complex integration, lack of modularity, and privacy and security concerns from data movement. This article proposes a more data-centric paradigm for embedding sensor intelligence on edge devices to combat these challenges. Our vision for &amp;lsquo;sensor 2.0&amp;rsquo; entails segregating sensor input data and ML processing from the wider system at the hardware level and providing a thin interface that mimics traditional sensors in functionality. This separation leads to a modular and easy-to-use ML sensor device. We discuss challenges presented by the standard approach of building ML processing into the software stack of the controlling microprocessor on an embedded system and how the modularity of ML sensors alleviates these problems. ML sensors increase privacy and accuracy while making it easier for system builders to integrate ML into their products as a simple component. We provide examples of prospective ML sensors and an illustrative datasheet as a demonstration and hope that this will build a dialogue to progress us towards sensor 2.0.</description>
    </item>
    
    <item>
      <title>RobotCore: An Open Architecture for Hardware Acceleration in ROS 2</title>
      <link>https://plancherb1.github.io/publication/robotcore/</link>
      <pubDate>Sun, 08 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://plancherb1.github.io/publication/robotcore/</guid>
      <description>We introduce RobotCore, an architecture to integrate hardware acceleration in the widely-used ROS 2 robotics software framework. This architecture is target-agnostic (supports edge, workstation, data center, or cloud targets) and accelerator-agnostic (supports both FPGAs and GPUs). It builds on top of the common ROS 2 build system and tools and is easily portable across different research and commercial solutions through a new firmware layer. We also leverage the Linux Tracing Toolkit next generation (LTTng) for low-overhead real-time tracing and benchmarking. To demonstrate the acceleration enabled by this architecture, we design an intra-FPGA ROS 2 node communication queue to enable faster data flows, and use it in conjunction with FPGA-accelerated nodes to achieve a 24.42% speedup over a CPU.</description>
    </item>
    
    <item>
      <title>TinyML: Applied AI for Development</title>
      <link>https://plancherb1.github.io/publication/tinymlunsti22/</link>
      <pubDate>Thu, 05 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://plancherb1.github.io/publication/tinymlunsti22/</guid>
      <description>We believe that TinyML has a significant role to play in achieving the SDGs and facilitating scientific research in areas such as environmental monitoring, physics of complex systems and energy management. To broaden access and participation and increase the impact of this new technology, we present an initiative that is creating and supporting a global network of academic institutions working on TinyML in developing countries. We suggest the development of additional open educational resources, Southâ€“South academic collaboration and pilot projects of at-scale TinyML solutions aimed at addressing the SDGs.</description>
    </item>
    
    <item>
      <title>TinyMLedu: The Tiny Machine Learning Open Education Initiative</title>
      <link>https://plancherb1.github.io/publication/tinymledu/</link>
      <pubDate>Thu, 03 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://plancherb1.github.io/publication/tinymledu/</guid>
      <description>&lt;a href=&#34;https://tinymledu.org&#34;&gt;TinyMLedu&lt;/a&gt; is working to build an international coalition of researchers and practitioners advancing TinyML in the developing world, and to develop and share high-quality, open-access educational materials globally.</description>
    </item>
    
    <item>
      <title>GRiD: GPU-Accelerated Rigid Body Dynamics with Analytical Gradients</title>
      <link>https://plancherb1.github.io/publication/grid/</link>
      <pubDate>Thu, 24 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://plancherb1.github.io/publication/grid/</guid>
      <description>We introduce and release GRiD, an open-source, GPU-accelerated library for computing rigid body dynamics with analytical gradients. GRiD was designed to accelerate nonlinear trajectory optimization through optimized code generation, GRiD provides as much as a 7.2x speedup over a state-of-the-art, multi-threaded CPU implementation and maintains as much as a 2.5x speedup when accounting for I/O overhead.</description>
    </item>
    
    <item>
      <title>Widening Access to Applied Machine Learning with TinyML</title>
      <link>https://plancherb1.github.io/publication/wideningaccesswithtinyml/</link>
      <pubDate>Thu, 27 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://plancherb1.github.io/publication/wideningaccesswithtinyml/</guid>
      <description>In this paper, we describe our pedagogical approach to increasing access to applied ML through a four part massive open online course (MOOC) on Tiny Machine Learning (TinyML) produced in collaboration between academia (Harvard University) and industry (Google). We suggest that TinyML, ML on resource-constrained embedded devices, is an attractive means to widen access because TinyML both leverages low-cost and globally accessible hardware, and encourages the development of complete, self-contained applications, from data collection to deployment. We also released the course materials publicly, hoping they will inspire the next generation of ML practitioners and educators and further broaden access to cutting-edge ML technologies.</description>
    </item>
    
    <item>
      <title>RoboRun: A Robot Runtime to Exploit Spatial Heterogeneity</title>
      <link>https://plancherb1.github.io/publication/roborun/</link>
      <pubDate>Sun, 01 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://plancherb1.github.io/publication/roborun/</guid>
      <description>This paper introduces RoboRun, a mobile-robot runtime that dynamically exploits the compute-environment synergy to improve performance and energy. We implement RoboRun in the Robot Operating System (ROS) and evaluate it on autonomous drones. We compare RoboRun against a state-of-the-art static design and show 4.5X and 4X improvements in mission time and energy, respectively, as well as a 36% reduction in CPU utilization.</description>
    </item>
    
    <item>
      <title>The Role of Compute in Autonomous Aerial Vehicles</title>
      <link>https://plancherb1.github.io/publication/roleofcompute/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://plancherb1.github.io/publication/roleofcompute/</guid>
      <description>By combining MAVBench (our tool-set, which consists of (1) a closed-loop real-time feedback simulator and (2) an end-to-end benchmark suite comprised of state-of-the-art kernels), analytical modeling, and an understanding of various compute impacts, we show up to 2X and 1.8X improvements for mission time and mission energy for two optimization case studies. Our investigations, as well as our optimizations, show that cyber-physical co-design, a methodology with which both the cyber and physical processes/quantities of the robot are developed with consideration of one another, similar to hardware-software co-design, is necessary for arriving at the design of the optimal robot.</description>
    </item>
    
    <item>
      <title>Robomorphic Computing: A Design Methodology for Domain-Specific Accelerators Parameterized by Robot Morphology</title>
      <link>https://plancherb1.github.io/publication/robomorphic/</link>
      <pubDate>Mon, 12 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://plancherb1.github.io/publication/robomorphic/</guid>
      <description>We introduce robomorphic computing; a methodology to transform robot morphology into a customized hardware accelerator morphology. In this work, we (i) present this design methodology; (ii) use the methodology to generate a parameterized accelerator design for the gradient of rigid body dynamics; (iii) evaluate FPGA and synthesized ASIC implementations; and (iv) describe how the design can be automatically customized for other robot models. Our FPGA accelerator achieves speedups of 8x and 86x over CPU and GPU latency, and maintains an overall speedup of 1.9x to 2.9x deployed in an end-to-end coprocessor system. ASIC synthesis indicates an additional factor of 7.2x.</description>
    </item>
    
    <item>
      <title>Accelerating Robot Dynamics Gradients on a CPU, GPU, and FPGA</title>
      <link>https://plancherb1.github.io/publication/accellrbdgrad/</link>
      <pubDate>Mon, 08 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://plancherb1.github.io/publication/accellrbdgrad/</guid>
      <description>In this paper, we detail the designs of three faster than state-of-the-art implementations of the gradient of rigid body dynamics on a CPU, GPU, and FPGA. Our optimized FPGA and GPU implementations provide as much as a 3.0x end-to-end speedup over our optimized CPU implementation by refactoring the algorithm to exploit its computational features, e.g., parallelism at different granularities.</description>
    </item>
    
  </channel>
</rss>
